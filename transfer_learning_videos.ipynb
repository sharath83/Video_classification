{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read a video\n",
    "- Sample frames from it (15 frames) 1- 13 - 1 (before fg, fg, after fg)\n",
    "- Extract fc7 activation layer from VGG net for every frame\n",
    "- Average activation values for all the frames of a video\n",
    "- use them as features in a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Video reading my cv2 stopped working since ffmpeg has some issue on my system. So using skvideo to read.\n",
    "from skvideo.io import VideoCapture\n",
    "import bisect\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/Users/homw/anaconda/envs/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.generic_utils import Progbar\n",
    "#Deep learning packages\n",
    "import theano\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.activations import relu\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Given a file name and number - samples frames according to foreground object distribution in a video'''\n",
    "def frame_sampling(fpath,n):\n",
    "    #Get first and last frames of the video\n",
    "    count_fg_f = []\n",
    "    count_fg_l = []\n",
    "    vid = VideoCapture(fpath)\n",
    "\n",
    "    success, frame_first = vid.read()\n",
    "    while success:\n",
    "        success, frame = vid.read()\n",
    "        if success:\n",
    "            frame_last = frame\n",
    "\n",
    "    frame_first = cv2.cvtColor(frame_first, cv2.COLOR_BGR2GRAY)\n",
    "    frame_last = cv2.cvtColor(frame_last, cv2.COLOR_BGR2GRAY)\n",
    "    #diff_l_f = cv2.absdiff(frame_last, frame_first)\n",
    "\n",
    "    #Find out the frames where foreground object starts, ends\n",
    "    #reset the indexer to the first frame\n",
    "    vid = VideoCapture(fpath)\n",
    "    success, frame = vid.read()\n",
    "    while success:\n",
    "        success, frame = vid.read()\n",
    "        if success:\n",
    "            frame_ng = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            diff_n_f = cv2.absdiff(frame_ng, frame_first)\n",
    "            diff_n_l = cv2.absdiff(frame_ng, frame_last)\n",
    "            _,diff_n_f = cv2.threshold(diff_n_f,80,255,cv2.THRESH_BINARY)\n",
    "            _,diff_n_l = cv2.threshold(diff_n_l,80,255,cv2.THRESH_BINARY)\n",
    "            #erode\n",
    "            kernel = np.ones((5,5), np.uint8)\n",
    "            diff_n_f = cv2.erode(diff_n_f, kernel, iterations=1)\n",
    "            diff_n_l = cv2.erode(diff_n_l, kernel, iterations=1)\n",
    "            # Accummulate fg counts with first frame and last frame\n",
    "            count_fg_f.append(np.count_nonzero(diff_n_f))\n",
    "            count_fg_l.append(np.count_nonzero(diff_n_l))\n",
    "    fg_start = bisect.bisect(count_fg_f, 500) #Frame where fg starts\n",
    "    fg_end = len(count_fg_l)-bisect.bisect(count_fg_l[::-1],500)-1 #Frame fg ends\n",
    "    end = len(count_fg_l)-1\n",
    "\n",
    "    # get n samples based on foreground object distribution\n",
    "    fg_diff = fg_end - fg_start\n",
    "    if fg_diff > 50:\n",
    "        sample = range(fg_start, fg_end,(fg_end-fg_start)/(n-1))\n",
    "        #print len(sample)\n",
    "        sample.insert(0,0)\n",
    "        if len(sample) >= n-1:\n",
    "            sample = sample[:n-1]\n",
    "        else: \n",
    "            while len(sample) != n-1:\n",
    "                sample.append(fg_end)\n",
    "\n",
    "        sample.append(end)\n",
    "    else:\n",
    "        sample = range(0,end, end/n)\n",
    "        sample = sample[:n]\n",
    "    print \"%s length is %d\" %(fpath, len(sample))\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sampled_frames(fpath,sample):\n",
    "    vid = VideoCapture(fpath)\n",
    "    frames=[]\n",
    "    \n",
    "    success, fr = vid.read()\n",
    "    #get zero frame\n",
    "    frx=cv2.resize(fr, (224,224))\n",
    "    frx = frx.astype(np.float32)\n",
    "    print frx.dtype\n",
    "    #read in RGB by skvideo, keeping the same format. cv2 would have read it in BGR format though!\n",
    "    frx[:,:,0] -= 123.68\n",
    "    frx[:,:,1] -= 116.779\n",
    "    frx[:,:,2] -= 103.909\n",
    "\n",
    "    frames.append(frx.astype(np.float32))\n",
    "    \n",
    "    #Get all the frames with sample index in the video\n",
    "    fr_index = 0\n",
    "    sam_index = 1\n",
    "    while success:\n",
    "        success, fr = vid.read()\n",
    "        # Get it - If the index stroed in samples == index of the current frame\n",
    "        if success and sam_index < len(sample):\n",
    "            fr_index += 1\n",
    "            if fr_index == sample[sam_index]:\n",
    "                sam_index += 1\n",
    "                frx=cv2.resize(fr, (224,224))\n",
    "                frx = frx.astype(np.float32)\n",
    "                frx[:,:,0] -= 123.68\n",
    "                frx[:,:,1] -= 116.779\n",
    "                frx[:,:,2] -= 103.909\n",
    "                frames.append(frx.astype(np.float32))\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
    "K. Simonyan, A. Zisserman\n",
    "arXiv:1409.1556'''\n",
    "#VGG16 model - ILSVRC - 2014 competition\n",
    "#Mean = [103.909, 116.779, 123.68]\n",
    "#BGR format\n",
    "#\n",
    "\n",
    "def VGG_16(weights_path = None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1), input_shape = (3,224,224)))\n",
    "    model.add(Convolution2D(64,3,3, activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64,3,3, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2,2), strides = (2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_network():\n",
    "    model = VGG_16('/Users/homw/Documents/petp/Yelp/vgg16_weights.h5')\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "\n",
    "    #Now get the layers of interest from VGG net\n",
    "    #We are interested in using the layers of net before the dense layer\n",
    "    my_out = model.layers[32].get_output(train = False)\n",
    "    input_layer = model.get_input(train = False)\n",
    "\n",
    "    my_net = theano.function([input_layer], my_out)\n",
    "       \n",
    "    return my_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = get_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Give the path to folder with all the videos\n",
    "path = '/Users/homw/Documents/MSDS16/IndStudy/videos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3132 - Fri Jan 15 10-24-13 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3132 - Fri Jan 15 10-24-13 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3132 - Fri Jan 15 14-44-18 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3132 - Fri Jan 15 14-44-18 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3132 - Fri Jan 15 15-47-38 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3132 - Fri Jan 15 15-47-38 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3132 - Fri Jan 15 19-15-07 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3132 - Fri Jan 15 19-15-07 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3132 - Fri Jan 15 19-15-44 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3132 - Fri Jan 15 19-15-44 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3132 - Sat Jan 16 09-59-18 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3132 - Sat Jan 16 09-59-18 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3132 - Sat Jan 16 11-32-30 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3132 - Sat Jan 16 11-32-30 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3132 - Sat Jan 16 11-33-30 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3132 - Sat Jan 16 11-33-30 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3132 - Sat Jan 16 13-05-10 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3132 - Sat Jan 16 13-05-10 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3132 - Sat Jan 16 17-38-29 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3132 - Sat Jan 16 17-38-29 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Fri Jan 15 11-23-35 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Fri Jan 15 11-23-35 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Fri Jan 15 11-37-56 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Fri Jan 15 11-37-56 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Fri Jan 15 17-43-50 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Fri Jan 15 17-43-50 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Fri Jan 15 18-43-35 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Fri Jan 15 18-43-35 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Sat Jan 16 08-13-18 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Sat Jan 16 08-13-18 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Sat Jan 16 08-13-57 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Sat Jan 16 08-13-57 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Sat Jan 16 09-41-55 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Sat Jan 16 09-41-55 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Sat Jan 16 17-03-45 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Sat Jan 16 17-03-45 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Sat Jan 16 17-06-45 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Sat Jan 16 17-06-45 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Thu Jan 14 17-59-26 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Thu Jan 14 17-59-26 2016.mp4 is ready for vggnet with size 15\n",
      "/Users/homw/Documents/MSDS16/IndStudy/videos/3135 - Thu Jan 14 17-59-56 2016.mp4 length is 15\n",
      "float32\n",
      "frames of 3135 - Thu Jan 14 17-59-56 2016.mp4 is ready for vggnet with size 15\n",
      "time taken is 6821 secs\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "features = []\n",
    "mean_feature = []\n",
    "num_frames = 15\n",
    "for f in os.listdir(path)[1:]:\n",
    "#vid_file = '3132 - Fri Jan 15 10-24-13 2016.mp4'\n",
    "    fpath = os.path.join(path, f)\n",
    "    sample = frame_sampling(fpath,num_frames)\n",
    "    frames = get_sampled_frames(fpath,sample)\n",
    "    \n",
    "    #Convert the sample frames of a video into a 4D array\n",
    "    frames = np.array(frames)\n",
    "    frames = frames.reshape(len(frames),3,224,224)\n",
    "    frames = frames.astype(np.float32)\n",
    "    \n",
    "    print \"frames of %s is ready for vggnet with size %d\" %(f,frames.shape[0])\n",
    "    #Get 4095 length feature vector for every frame - size num_frames X 4095\n",
    "    vid_feature = net(frames)\n",
    "    #Get the mean feature out of all the sampled frames and store it\n",
    "    mean_feature.append(np.mean(vid_feature, axis=0))\n",
    "    #store frame level features\n",
    "    features.append(vid_feature)\n",
    "print \"time taken is %d secs\" %((time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(mean_feature)\n",
    "np.save(\"mean_feature.npy\",X)\n",
    "data = pd.read_csv(\"video_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"all_fatures.npy\", np.array(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = data.ix[:,\"actual label\"]\n",
    "mlb = MultiLabelBinarizer()\n",
    "target = mlb.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Day</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>RoomNo</th>\n",
       "      <th>Time_hh</th>\n",
       "      <th>Time_mm</th>\n",
       "      <th>Time_ss</th>\n",
       "      <th>Year</th>\n",
       "      <th>Act_MedSink</th>\n",
       "      <th>Act_ItemsPlaced</th>\n",
       "      <th>Act_HandWash</th>\n",
       "      <th>Act_Others</th>\n",
       "      <th>actual label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>Fri</td>\n",
       "      <td>3132 - Fri Jan 15 10-24-13 2016</td>\n",
       "      <td>Jan</td>\n",
       "      <td>3132</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Fri</td>\n",
       "      <td>3132 - Fri Jan 15 14-44-18 2016</td>\n",
       "      <td>Jan</td>\n",
       "      <td>3132</td>\n",
       "      <td>14</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Fri</td>\n",
       "      <td>3132 - Fri Jan 15 15-47-38 2016</td>\n",
       "      <td>Jan</td>\n",
       "      <td>3132</td>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Fri</td>\n",
       "      <td>3132 - Fri Jan 15 19-15-07 2016</td>\n",
       "      <td>Jan</td>\n",
       "      <td>3132</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>Fri</td>\n",
       "      <td>3132 - Fri Jan 15 19-15-44 2016</td>\n",
       "      <td>Jan</td>\n",
       "      <td>3132</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Day Day_of_week                        File_Name Month  RoomNo  \\\n",
       "0           0   15         Fri  3132 - Fri Jan 15 10-24-13 2016   Jan    3132   \n",
       "1           1   15         Fri  3132 - Fri Jan 15 14-44-18 2016   Jan    3132   \n",
       "2           2   15         Fri  3132 - Fri Jan 15 15-47-38 2016   Jan    3132   \n",
       "3           3   15         Fri  3132 - Fri Jan 15 19-15-07 2016   Jan    3132   \n",
       "4           4   15         Fri  3132 - Fri Jan 15 19-15-44 2016   Jan    3132   \n",
       "\n",
       "   Time_hh  Time_mm  Time_ss  Year  Act_MedSink  Act_ItemsPlaced  \\\n",
       "0       10       24       13  2016            0                1   \n",
       "1       14       44       18  2016            0                1   \n",
       "2       15       47       38  2016            0                1   \n",
       "3       19       15        7  2016            0                0   \n",
       "4       19       15       44  2016            0                0   \n",
       "\n",
       "   Act_HandWash  Act_Others actual label  \n",
       "0             1           0            R  \n",
       "1             0           0            I  \n",
       "2             1           0            H  \n",
       "3             0           1            P  \n",
       "4             0           1            P  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=1000, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train a binary classfier for Handwash\n",
    "#In the same way other activities \"M\", \"I\", \"R\", \"P\" can be tried.\n",
    "target = data.ix[:,\"actual label\"]\n",
    "handwash = [1 if i == \"H\" else 0 for i in target]\n",
    "print handwash\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=1000, verbose=0)\n",
    "rf.fit(X[:21,:], handwash[:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.9 ,  0.1 ],\n",
       "        [ 0.97,  0.03],\n",
       "        [ 0.98,  0.02],\n",
       "        [ 1.  ,  0.  ],\n",
       "        [ 1.  ,  0.  ],\n",
       "        [ 0.92,  0.08],\n",
       "        [ 0.94,  0.06],\n",
       "        [ 0.94,  0.06],\n",
       "        [ 0.98,  0.02],\n",
       "        [ 0.94,  0.06],\n",
       "        [ 0.87,  0.13],\n",
       "        [ 0.85,  0.15],\n",
       "        [ 0.27,  0.73],\n",
       "        [ 0.91,  0.09],\n",
       "        [ 0.17,  0.83],\n",
       "        [ 0.11,  0.89],\n",
       "        [ 0.82,  0.18],\n",
       "        [ 0.12,  0.88],\n",
       "        [ 0.23,  0.77],\n",
       "        [ 0.97,  0.03],\n",
       "        [ 0.97,  0.03]]),\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted Probabilities\n",
    "rf.predict_proba(X), handwash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Not used in the code!!\n",
    "#Getting weights for each layer. But it is very easy to use theano function to get the \n",
    "#activations of the layer of interest\n",
    "weight_dic = {}\n",
    "n=0\n",
    "for layer in model.layers:\n",
    "    w = layer.get_weights()\n",
    "    weight_dic[n] = w\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weight_dic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
